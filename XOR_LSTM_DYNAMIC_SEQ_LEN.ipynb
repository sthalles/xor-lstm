{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR LSTM\n",
    "\n",
    "Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequenceâ€™s end. Test the two approaches below:\n",
    "\n",
    "- Generate a dataset of random 100,000 binary strings of length 50. Train the LSTM; what performance do you get?\n",
    "\n",
    "- Generate a dataset of random 100,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "- The RNN seems to work only with small sequence sizes. Less than 6\n",
    "- Even if I increase the number of epochs or change the lr, it does not fit\n",
    "\n",
    "- Sometimes, I run the same experiemnt, with the same seq length and the model alternates between fitting and not fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.random.binomial(1, 0.5, (100000, 50, 1))\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sequences = 100000\n",
    "max_sequence_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sequences of more than 2 bits, the XOR function should output TRUE when the number of TRUE values is odd (in the sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "\n",
    "bucketing_dataset = {}\n",
    "bucketing_labels = {}\n",
    "\n",
    "for i in range(number_of_sequences):\n",
    "    seq_len = np.random.choice(range(1,max_sequence_length+1))\n",
    "    record = np.random.choice(2, [seq_len]).astype(np.float32)\n",
    "    \n",
    "    label = np.count_nonzero(record)\n",
    "    \n",
    "    # calculate the pararity between pixels\n",
    "    if label % 2 == 0: # even\n",
    "        sequence_label = 0\n",
    "    else: # odd\n",
    "        # For sequences of more than 2 bits, the XOR function should output TRUE when\n",
    "        # the number of TRUE values is odd (in the sequence)\n",
    "        sequence_label = 1\n",
    "    \n",
    "    if len(record) not in bucketing_dataset:\n",
    "        bucketing_dataset[len(record)] = [record]\n",
    "        bucketing_labels[len(record)] = [sequence_label]\n",
    "    else:\n",
    "        bucketing_dataset[len(record)].append(record)\n",
    "        bucketing_labels[len(record)].append(sequence_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(888)\n",
    "\n",
    "testing_data = []\n",
    "testing_labels = []\n",
    "\n",
    "for i in range(10000):\n",
    "    seq_len = np.random.choice(range(1,max_sequence_length+1))\n",
    "    record = np.random.choice(2, [seq_len]).astype(np.float32)\n",
    "    testing_data.append(record)\n",
    "    \n",
    "    label = np.count_nonzero(record)\n",
    "    if label % 2 == 0: # even\n",
    "        testing_labels.append(0)\n",
    "    else: # odd\n",
    "        # For sequences of more than 2 bits, the XOR function should output TRUE when\n",
    "        # the number of TRUE values is odd (in the sequence)\n",
    "        testing_labels.append(1)\n",
    "    \n",
    "testing_data = np.asarray(testing_data)\n",
    "testing_labels = np.asarray(testing_labels)\n",
    "\n",
    "print(testing_data.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape: (10000,)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing data shape:\", testing_data.shape)\n",
    "print(\"Testing labels shape:\", testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bucketize_dataset(input_data, input_labels):\n",
    "#     bucketing_dataset = {} # {\"1\": [0],[1],[0],...], \"2\": [[1,1],[0,0],[0,1]...]]}\n",
    "#     bucketing_labels = {}\n",
    "#     for id_, record in enumerate(input_data):\n",
    "#         if len(record) not in bucketing_dataset:\n",
    "#             bucketing_dataset[len(record)] = [record]\n",
    "#             bucketing_labels[len(record)] = [input_labels[id_]]\n",
    "#         else:\n",
    "#             bucketing_dataset[len(record)].append(record)\n",
    "#             bucketing_labels[len(record)].append(input_labels[id_])\n",
    "#     return bucketing_dataset, bucketing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = bucketize_dataset(X_train, y_train)\n",
    "# X_test, y_test = bucketize_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(dataset, labels, batch_size=32, max_seq_len=50):\n",
    "    # generate a list of bucket ids, list: [0,1,2,3,4,5,...,50]\n",
    "    bucket_ids = list(range(1,max_seq_len+1))\n",
    "    np.random.shuffle(bucket_ids)\n",
    "    \n",
    "    for bucket_id in bucket_ids:\n",
    "        # get subset with with equal sequence length, e.g. get all sequences with 15 elements long\n",
    "        bucket_input = np.array(dataset[bucket_id])\n",
    "        bucket_labels = np.array(labels[bucket_id])\n",
    "        \n",
    "        # random batch [batch_size] elements from the sequences with equal length\n",
    "        batch_ids = np.random.choice(range(bucket_input.shape[0]),size=batch_size)\n",
    "        yield np.expand_dims(bucket_input[batch_ids],2), bucket_labels[batch_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch, labels in next_batch(bucketing_dataset,bucketing_labels, batch_size=4, max_seq_len=max_sequence_length):\n",
    "#     #print(batch.shape)\n",
    "#     #print(len(batch))\n",
    "#     print(batch)\n",
    "#     print(labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0,1], [counter[0], counter[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_samples = tf.placeholder(shape=[None,None,1], dtype=tf.float32)\n",
    "batch_labels = tf.placeholder(shape=[None], dtype=tf.uint8)\n",
    "batch_size = tf.placeholder(shape=(), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(input_data, num_layers=3):\n",
    "#     # create a BasicRNNCell\n",
    "#     rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=256)\n",
    "\n",
    "#     # defining initial state\n",
    "#     initial_state = rnn_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    \n",
    "    # create 2 LSTMCells\n",
    "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [128, 256]]\n",
    "\n",
    "    # create a RNN cell composed sequentially of a number of RNNCells\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    # 'outputs' is a tensor of shape [batch_size, max_time, cell_state_size]\n",
    "    # 'state' is a tensor of shape [batch_size, cell_state_size]\n",
    "    outputs, state = tf.nn.dynamic_rnn(multi_rnn_cell, input_data,\n",
    "                                       # initial_state=initial_state,\n",
    "                                       dtype=tf.float32)\n",
    "    \n",
    "    print(outputs)\n",
    "    out = tf.layers.flatten(state[-1][-1])\n",
    "    logits = tf.layers.dense(out, 2, activation=None)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = RNN(batch_samples)\n",
    "#logits = DNN(batch_samples)\n",
    "    \n",
    "predictions = tf.argmax(logits, axis=1)\n",
    "\n",
    "# accuracy\n",
    "correct_predictions = tf.equal(predictions, tf.cast(batch_labels, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.to_float(correct_predictions))\n",
    "\n",
    "log_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.one_hot(batch_labels, 2), logits=logits)\n",
    "cost = tf.reduce_mean(log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0006)\n",
    "\n",
    "model_vars = tf.trainable_variables()\n",
    "gradients = tf.gradients(cost, model_vars)\n",
    "#gradients, _ = tf.clip_by_global_norm(gradients, 5.) # gradient clipping\n",
    "\n",
    "minimize = optimizer.apply_gradients(zip(gradients, model_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "\n",
    "train_batch_size = 32\n",
    "test_batch_size = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(1000):\n",
    "        counter += 1\n",
    "\n",
    "        for X_batch, y_batch in next_batch(bucketing_dataset, bucketing_labels, \n",
    "                                           batch_size=train_batch_size, \n",
    "                                           max_seq_len=max_sequence_length):\n",
    "\n",
    "            _, train_acc, train_loss = sess.run([minimize, accuracy_op, cost], \n",
    "                                                feed_dict={batch_samples: X_batch,\n",
    "                                                           batch_labels: y_batch,\n",
    "                                                           batch_size: len(X_batch)})\n",
    "            training_loss.append(train_loss)\n",
    "            training_acc.append(train_acc)\n",
    "\n",
    "    validation_acc = []\n",
    "    validation_loss = []\n",
    "\n",
    "    for X_batch, y_batch in zip(testing_data, testing_labels):\n",
    "        X_batch = np.reshape(X_batch, (1,len(X_batch),1))\n",
    "        y_batch = np.array([y_batch])\n",
    "\n",
    "        val_acc, val_cost = sess.run([accuracy_op, cost], feed_dict={batch_samples: X_batch,\n",
    "                                                                     batch_labels: y_batch,\n",
    "                                                                     batch_size: len(X_batch)})\n",
    "        validation_loss.append(val_cost)\n",
    "        validation_acc.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_loss)\n",
    "#plt.plot(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Mean acc:\", np.mean(training_acc))\n",
    "print(\"Test Mean acc:\", np.mean(validation_acc))\n",
    "\n",
    "plt.plot(training_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(validation_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
